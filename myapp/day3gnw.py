# -*- coding: utf-8 -*-
"""Day3GNW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n-UWShMXMad7k3ADGpjO87k0Lny84mHh
"""

#import the packages 
import numpy as np,pandas as pd,sklearn
import warnings
import os
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

warnings.filterwarnings("ignore")

titanic_data = pd.read_csv(os.path.join(BASE_DIR, 'titanic.csv'))
titanic_data.head()

titanic_data.columns

#To check the count of  missing values
titanic_data.isnull().sum()

print("No of passengers travelling in ship or in original data:"+str(len(titanic_data)))

#Data Visualization 
import matplotlib.pyplot as plt,seaborn as sns
#titanic_data["Age"].plot.hist()
#plt.show()

#sns.boxplot(x="Embarked",y="Age",data=titanic_data)
#plt.show()

#sns.boxplot(x="Sex",y="Age",data=titanic_data)
#plt.show()

#drop the major missing values
titanic_data.drop("Cabin",axis=1,inplace=True)

titanic_data.isnull().sum()

#Fill the values of Age column
titanic_data["Age"].fillna((titanic_data["Age"].mean()),inplace=True)

titanic_data.isnull().sum()

#To drop all null values
titanic_data.dropna(inplace=True)

titanic_data.isnull().sum()

titanic_data.info()

#To create dummies
sex = pd.get_dummies(titanic_data["Sex"],drop_first=True)
sex.head()

Pcl = pd.get_dummies(titanic_data["Pclass"],drop_first=True)
Pcl.head()

embark = pd.get_dummies(titanic_data["Embarked"],drop_first=True)
embark.head()

titanic_data = pd.concat([titanic_data,sex,Pcl,embark],axis=1)
titanic_data.head(2)

#Drop the unnecessary columns
titanic_data.drop(['Sex','Embarked','Pclass','Name','Ticket','PassengerId'],
                  axis=1,inplace =True)
titanic_data.head()

#Training and Testing data
X = titanic_data.drop('Survived',axis=1)
y = titanic_data["Survived"]

from sklearn.model_selection import train_test_split

#random state is basically used for reproducing your problem every time
a,b = np.arange(10).reshape(5,2),range(5)
b

train_test_split(a,b)

train_test_split(a,b)

train_test_split(a,b,random_state=1)

train_test_split(a,b,random_state=1)

#Splitting the data into training and testing set
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=1)
from sklearn.linear_model import LogisticRegression
logmodel = LogisticRegression()
logmodel.fit(X_train,y_train) #Estimators

#predictors
predictions = logmodel.predict(X_test)

def survivalpredict(X_test):
  return logmodel.predict(X_test)

'''#Metrics
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
print(accuracy_score(y_test,predictions)*100)

print(confusion_matrix(y_test,predictions))

print(classification_report(y_test,predictions))

predictions = logmodel.predict([[22.0,1,0,7.2500,1,0,1,0,1]])
predictions

#!pip install flask-ngrok

from flask_ngrok import run_with_ngrok
from flask import Flask,jsonify
app = Flask(__name__)
run_with_ngrok(app) #starts ngrok when app is running
@app.route("/<float:Age>/<int:SibSp>/<int:Parch>/<float:Fare>/<Gender>/<int:Pclass>/<Place>")'''
def home(Age,SibSp,Parch,Fare,Gender,Pclass,Place):
  p = []
  p +=[Age,SibSp,Parch,Fare]
  if Gender.casefold() == "m":
    p+=[1]
  else:
    p+=[0]
  if Pclass == 2:
    p+=[1,0]
  elif Pclass == 3:
    p+=[0,1]
  else:
    p+=[0,0]
  if Place.casefold() == "queenstown":
    p+=[1,0]
  elif Place.casefold() == "southampton":
    p+=[0,1]
  else:
    p+=[0,0]
  arr = np.array([p])
  predict = logmodel.predict(arr)
  if predict == [1]:
    result = {'result':'Survived'}
  else:
    result = {'result':'Not Survived'}
  return (result)

'''if __name__ == '__main__':
  app.run()'''

